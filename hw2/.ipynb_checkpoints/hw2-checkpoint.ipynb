{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e3a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19430fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS, N_COLS, N_WIN = 3, 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327d872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe(gym.Env):\n",
    "    def __init__(self, n_rows=N_ROWS, n_cols=N_COLS, n_win=N_WIN, clone=None):\n",
    "        if clone is not None:\n",
    "            self.n_rows, self.n_cols, self.n_win = clone.n_rows, clone.n_cols, clone.n_win\n",
    "            self.board = copy.deepcopy(clone.board)\n",
    "            self.curTurn = clone.curTurn\n",
    "            self.gameOver = clone.gameOver\n",
    "            self.emptySpaces = None\n",
    "            self.boardHash = None\n",
    "        else:\n",
    "            self.n_rows = n_rows\n",
    "            self.n_cols = n_cols\n",
    "            self.n_win = n_win\n",
    "            self.gameOver = False\n",
    "\n",
    "            self.reset()\n",
    "\n",
    "    def getEmptySpaces(self):\n",
    "        if self.emptySpaces is None:\n",
    "            res = np.where(self.board == 0)\n",
    "            self.emptySpaces = np.array([ (i, j) for i,j in zip(res[0], res[1]) ])\n",
    "        return self.emptySpaces\n",
    "\n",
    "    def makeMove(self, player, i, j):\n",
    "        self.board[i, j] = player\n",
    "        self.emptySpaces = None\n",
    "        self.boardHash = None\n",
    "\n",
    "    def getHash(self):\n",
    "        if self.boardHash is None:\n",
    "            self.boardHash = ''.join(['%s' % (x+1) for x in self.board.reshape(self.n_rows * self.n_cols)])\n",
    "        return self.boardHash\n",
    "    \n",
    "    def decodeHash(self, boardHash):\n",
    "        return tuple(list(map(int,list(boardHash))))    \n",
    "    \n",
    "    def giveObsSpace(self):\n",
    "        return tuple(3 for _ in range(self.n_cols*self.n_rows))\n",
    "    \n",
    "    def giveActSpace(self):\n",
    "        return self.n_cols*self.n_rows\n",
    "\n",
    "    def isTerminal(self):\n",
    "        # проверим, не закончилась ли игра\n",
    "        cur_marks, cur_p = np.where(self.board == self.curTurn), self.curTurn\n",
    "        for i,j in zip(cur_marks[0], cur_marks[1]):\n",
    "            win = False\n",
    "            if i <= self.n_rows - self.n_win:\n",
    "                if np.all(self.board[i:i+self.n_win, j] == cur_p):\n",
    "                    win = True\n",
    "            if not win:\n",
    "                if j <= self.n_cols - self.n_win:\n",
    "                    if np.all(self.board[i,j:j+self.n_win] == cur_p):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j <= self.n_cols - self.n_win:\n",
    "                    if np.all(np.array([ self.board[i+k,j+k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if not win:\n",
    "                if i <= self.n_rows - self.n_win and j >= self.n_win-1:\n",
    "                    if np.all(np.array([ self.board[i+k,j-k] == cur_p for k in range(self.n_win) ])):\n",
    "                        win = True\n",
    "            if win:\n",
    "                self.gameOver = True\n",
    "                return self.curTurn\n",
    "\n",
    "        if len(self.getEmptySpaces()) == 0:\n",
    "            self.gameOver = True\n",
    "            return 0\n",
    "        #self.gameOver = False\n",
    "        return None\n",
    "\n",
    "    def printBoard(self):\n",
    "        for i in range(0, self.n_rows):\n",
    "            print('----'*(self.n_cols)+'-')\n",
    "            out = '| '\n",
    "            for j in range(0, self.n_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('----'*(self.n_cols)+'-')\n",
    "\n",
    "    def getState(self):\n",
    "        return (self.getHash(), self.getEmptySpaces(), self.curTurn)\n",
    "\n",
    "    def action_from_int(self, action_int):\n",
    "        return ( int(action_int / self.n_cols), int(action_int % self.n_cols))\n",
    "\n",
    "    def int_from_action(self, action):\n",
    "        return action[0] * self.n_cols + action[1]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if self.board[action[0], action[1]] != 0:\n",
    "            return self.getState(), -10 * self.curTurn, True, {}\n",
    "        self.makeMove(self.curTurn, action[0], action[1])\n",
    "        reward = self.isTerminal()\n",
    "        #if reward is None:\n",
    "        self.curTurn = -self.curTurn\n",
    "        return self.getState(), 0 if reward is None else reward, reward is not None, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((self.n_rows, self.n_cols), dtype=int)\n",
    "        self.boardHash = None\n",
    "        self.gameOver = False\n",
    "        self.emptySpaces = None\n",
    "        self.curTurn = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4a96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board(env, pi, showtext=True, verbose=True, fontq=20, fontx=60):\n",
    "    '''Рисуем доску с оценками из стратегии pi'''\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    X, Y = np.meshgrid(np.arange(0, env.n_rows), np.arange(0, env.n_rows))\n",
    "    Z = np.zeros((env.n_rows, env.n_cols)) + .01\n",
    "    s, actions = env.getHash(), env.getEmptySpaces()\n",
    "    if pi is not None and s in pi.Q:\n",
    "        for i, a in enumerate(actions):\n",
    "            Z[a[0], a[1]] = pi.Q[s][i]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    surf = ax.imshow(Z, cmap=plt.get_cmap('Accent', 10), vmin=-1, vmax=1)\n",
    "    if showtext:\n",
    "        for i,a in enumerate(actions):\n",
    "            if pi is not None and s in pi.Q:\n",
    "                ax.text( a[1] , a[0] , \"%.3f\" % pi.Q[s][i], fontsize=fontq, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "    for i in range(env.n_rows):\n",
    "        for j in range(env.n_cols):\n",
    "            if env.board[i, j] == -1:\n",
    "                ax.text(j, i, \"O\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "            if env.board[i, j] == 1:\n",
    "                ax.text(j, i, \"X\", fontsize=fontx, horizontalalignment='center', verticalalignment='center', color=\"w\" )\n",
    "#     cbar = plt.colorbar(surf, ticks=[0, 1])\n",
    "    ax.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def get_and_print_move(env, pi, s, actions, random=False, verbose=True, fontq=20, fontx=60):\n",
    "    '''Делаем ход, рисуем доску'''\n",
    "    plot_board(env, pi, fontq=fontq, fontx=fontx)\n",
    "    if verbose and (pi is not None):\n",
    "        if s in pi.Q:\n",
    "            for i,a in enumerate(actions):\n",
    "                print(i, a, pi.Q[s][i])\n",
    "        else:\n",
    "            print(\"Стратегия не знает, что делать...\")\n",
    "    if random:\n",
    "        return np.random.randint(len(actions))\n",
    "    else:\n",
    "        return pi.getActionGreedy(s, len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a673ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_game(env, pi1, pi2, random_crosses=False, random_naughts=True, verbose=True, fontq=20, fontx=60):\n",
    "    '''Играем тестовую партию между стратегиями или со случайными ходами, рисуем ход игры'''\n",
    "    done = False\n",
    "    env.reset()\n",
    "    while not done:\n",
    "        s, actions = env.getHash(), env.getEmptySpaces()\n",
    "        if env.curTurn == 1:\n",
    "            a = get_and_print_move(env, pi1, s, actions, random=random_crosses, verbose=verbose, fontq=fontq, fontx=fontx)\n",
    "        else:\n",
    "            a = get_and_print_move(env, pi2, s, actions, random=random_naughts, verbose=verbose, fontq=fontq, fontx=fontx)\n",
    "        observation, reward, done, info = env.step(actions[a])\n",
    "        if reward == 1:\n",
    "            print(\"Крестики выиграли!\")\n",
    "            plot_board(env, None, showtext=False, fontq=fontq, fontx=fontx)\n",
    "        if reward == -1:\n",
    "            print(\"Нолики выиграли!\")\n",
    "            plot_board(env, None, showtext=False, fontq=fontq, fontx=fontx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=7, n_cols=7, n_win=4)\n",
    "plot_test_game(env, None, None, random_crosses=True, random_naughts=True, verbose=True, fontx=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff99187",
   "metadata": {},
   "source": [
    "# Часть 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "752e3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning:\n",
    "    def __init__(self, state_space, action_space, player=1, eps=0.1, alpha=0.1, gamma=1):\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.s_space = state_space\n",
    "        self.a_space = action_space\n",
    "        self.actions = np.arange(action_space)\n",
    "        self.Q = np.zeros((*state_space, action_space))\n",
    "        self.player = player\n",
    "    \n",
    "    def step(self, state, next_state, action, reward):\n",
    "        self.Q[state][action] += self.alpha * (reward * self.player + self.gamma * self.Q[next_state].max() - self.Q[state][action])\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.eps:\n",
    "            return np.random.choice(self.actions)\n",
    "        return self.Q[state].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37762caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent1, agent2, env, steps):\n",
    "    x_d_o = [0, 0, 0]\n",
    "    actions = deque(maxlen=2)\n",
    "    states = deque(maxlen=3)\n",
    "    counter = 0\n",
    "    for i in tqdm(range(steps)):\n",
    "        env.reset()\n",
    "        sHash, _, _ = env.getState()\n",
    "        states.append(env.decodeHash(sHash))\n",
    "        actions.append(agent1.act(states[-1]))\n",
    "        observation, reward, done, inf = env.step(env.action_from_int(actions[-1]))\n",
    "        states.append(env.decodeHash(observation[0]))\n",
    "        while done is not True:\n",
    "            turn = observation[2]\n",
    "            if turn == 1:\n",
    "                actions.append(agent1.act(states[-1]))\n",
    "            else:\n",
    "                actions.append(agent2.act(states[-1]))\n",
    "            \n",
    "            observation, reward, done, inf = env.step(env.action_from_int(actions[-1]))\n",
    "            states.append(env.decodeHash(observation[0]))\n",
    "            if abs(reward) > 1:\n",
    "                if turn == 1:\n",
    "                    agent1.step(states[1], states[2], actions[1], reward)\n",
    "                else:\n",
    "                    agent2.step(states[1], states[2], actions[1], reward)\n",
    "            else:\n",
    "            \n",
    "                if turn == 1:\n",
    "                    agent2.step(states[0], states[2], actions[0], reward)\n",
    "                else:\n",
    "                    agent1.step(states[0], states[2], actions[0], reward)\n",
    "        if reward > 0:\n",
    "            x_d_o[0] += 1\n",
    "        elif reward == 0:\n",
    "            x_d_o[1] += 1\n",
    "        else:\n",
    "            x_d_o[2] += 1\n",
    "        \n",
    "        if abs(reward) <= 1:\n",
    "            counter += 1\n",
    "        \n",
    "        if i % 100000==0:\n",
    "            print(counter)\n",
    "            print(x_d_o)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6edf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=3, n_cols=3, n_win=3)\n",
    "obs_space = env.giveObsSpace()\n",
    "act_space = env.giveActSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a61b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_x = Qlearning(obs_space, act_space)\n",
    "agent_o = Qlearning(obs_space, act_space, player=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8de1baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                    | 216/500000 [00:00<08:12, 1015.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████▊                           | 100173/500000 [02:01<08:05, 823.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64431\n",
      "[22573, 55045, 22383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████▌                    | 200252/500000 [04:01<05:48, 859.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131972\n",
      "[45554, 110845, 43602]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████▍             | 300184/500000 [06:03<04:06, 809.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199909\n",
      "[68565, 166798, 64638]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████▏      | 400212/500000 [08:05<02:10, 763.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267965\n",
      "[91368, 222941, 85692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 500000/500000 [10:09<00:00, 820.97it/s]\n"
     ]
    }
   ],
   "source": [
    "train(agent_x, agent_o, env, int(5e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98d6846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent1, agent2, env, n=100):\n",
    "    agent1.eps = 0\n",
    "    agent2.eps = 0\n",
    "    total_reward = 0\n",
    "    for game in range(n):\n",
    "        env.reset()\n",
    "        done = False\n",
    "        sHash, _, _ = env.getState()\n",
    "        state = env.decodeHash(sHash)\n",
    "        while not done:\n",
    "            act = agent1.act(state)\n",
    "            obs, rew, done, _ = env.step(env.action_from_int(act))\n",
    "            if done:\n",
    "                break\n",
    "            state = env.decodeHash(obs[0])\n",
    "            act = agent2.act(state)\n",
    "            obs, rew, done, _ = env.step(env.action_from_int(act))\n",
    "            if done:\n",
    "                break\n",
    "            state = env.decodeHash(obs[0])\n",
    "        total_reward += rew\n",
    "        #env.printBoard()\n",
    "    return total_reward / n\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17fec6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(agent_x, agent_o, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a530a",
   "metadata": {},
   "source": [
    "агенты обучились играть друг с другом и выходят на ничью"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da071cf",
   "metadata": {},
   "source": [
    "Более сложная среда. При увеличении n_rows и n_cols увеличивается размер таблицы Q, при чём экспоненциально (3^(n_cols*n_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab480c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe(n_rows=4, n_cols=4, n_win=3)\n",
    "obs_space = env.giveObsSpace()\n",
    "act_space = env.giveActSpace()\n",
    "agent_x = Qlearning(obs_space, act_space)\n",
    "agent_o = Qlearning(obs_space, act_space, player=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b274f31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                     | 65/1000000 [00:00<25:42, 648.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▎                             | 100088/1000000 [03:07<29:45, 504.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15813\n",
      "[51562, 268, 48171]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████▌                          | 200123/1000000 [06:35<32:33, 409.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57537\n",
      "[117386, 619, 81996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████▉                       | 300123/1000000 [09:50<21:21, 546.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118115\n",
      "[194546, 894, 104561]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████▏                   | 400064/1000000 [12:47<19:37, 509.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179735\n",
      "[271348, 976, 127677]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████▌                | 500197/1000000 [15:50<12:10, 684.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241555\n",
      "[347696, 1094, 151211]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████▊             | 600140/1000000 [18:55<15:09, 439.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303297\n",
      "[423938, 1243, 174820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████          | 700185/1000000 [21:58<08:25, 593.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365381\n",
      "[500028, 1598, 198375]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████▍      | 800096/1000000 [25:04<07:27, 446.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427993\n",
      "[576217, 1827, 221957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████▋   | 900149/1000000 [28:01<03:13, 515.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490642\n",
      "[651850, 2214, 245937]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 1000000/1000000 [30:57<00:00, 538.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train(agent_x, agent_o, env, int(1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a8834",
   "metadata": {},
   "source": [
    "Крестики побеждают в большинстве случаев, так и должно быть. Алгоритм обучается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1fa64ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(agent_x, agent_o, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf76a74",
   "metadata": {},
   "source": [
    "# Часть 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b6b8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2595bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "BATCH_SIZE = 1\n",
    "GAMMA = 0.99\n",
    "TAU = 0.1\n",
    "EPS = 0.15\n",
    "PER_UPDATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad1fad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    def __init__(self, player=1):\n",
    "        self.steps = 0\n",
    "        self.player = player\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Conv2d(1,9,3),\n",
    "        nn.ELU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(9, 9),\n",
    "        nn.ELU(),\n",
    "        nn.Linear(9, 9)            \n",
    "        )\n",
    "        self.target_model = deepcopy(self.model)\n",
    "        self.buffer = deque(maxlen=9)\n",
    "        self.optimizer = Adam(self.model.parameters(), lr=LR)\n",
    "        self.criterion = nn.SmoothL1Loss()\n",
    "        self.actions = np.arange(9)\n",
    "        self.eps = 0.1\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        batch = random.sample(self.buffer, BATCH_SIZE)\n",
    "        batch = list(zip(*batch))\n",
    "        return batch\n",
    "    \n",
    "    def soft_update(self):\n",
    "        for tp, sp in zip(self.target_model.parameters(), self.model.parameters()):\n",
    "            tp.data.copy_((1 - TAU) * tp.data + TAU * sp.data)\n",
    "    \n",
    "    def step(self, batch):\n",
    "        \n",
    "        state, action, next_state, reward, done = batch\n",
    "        \n",
    "        state = torch.tensor(np.array(state, dtype=np.float32))\n",
    "        action = np.array(action, dtype=np.int)\n",
    "        next_state = torch.tensor(np.array(next_state, dtype=np.float32))\n",
    "        reward = torch.tensor(np.array(reward, dtype=np.float32)*self.player)\n",
    "        done = torch.tensor(np.array(done, dtype=np.float32))\n",
    "        \n",
    "        Q = self.model(state)[np.arange(BATCH_SIZE), action]\n",
    "        QT = self.target_model(next_state)\n",
    "        QT[done==True] = 0\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        target = reward + GAMMA * QT.max(dim=1)[0]\n",
    "        loss = self.criterion(Q, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.steps % 32 == 0:\n",
    "            self.target_model = deepcopy(self.model)\n",
    "        \n",
    "    \n",
    "    def update(self, transition):\n",
    "        self.steps += 1\n",
    "        self.buffer.append(transition)\n",
    "        if len(self.buffer)==9 and self.steps % PER_UPDATE==0:\n",
    "            batch = self.sample_batch()\n",
    "            self.step(batch)\n",
    "    \n",
    "    def act(self, state, possible, env):\n",
    "        if np.random.rand() <= self.eps:\n",
    "            idx = np.random.randint(len(possible))\n",
    "            return env.int_from_action(possible[idx])\n",
    "        state = torch.tensor(np.array(state, dtype=np.float32)).unsqueeze(0)\n",
    "        act = self.model(state).argmax()\n",
    "        return act.item()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8653ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent1, agent2, env, steps):\n",
    "    x_d_o = [0, 0, 0]\n",
    "    actions = deque(maxlen=2)\n",
    "    states = deque(maxlen=3)\n",
    "    counter = 0\n",
    "    k = 0\n",
    "    xo = [0,0]\n",
    "    for i in tqdm(range(steps)):\n",
    "        env.reset()\n",
    "        sHash, possible, _ = env.getState()\n",
    "        states.append([deepcopy(env.board)])\n",
    "        actions.append(agent1.act(states[-1], possible, env))\n",
    "        observation, reward, done, inf = env.step(env.action_from_int(actions[-1]))\n",
    "        states.append([deepcopy(env.board)])\n",
    "        while done is not True:\n",
    "            turn = observation[2]\n",
    "            possible = observation[1]\n",
    "            if turn == 1:\n",
    "                actions.append(agent1.act(states[-1], possible, env))\n",
    "            else:\n",
    "                actions.append(agent2.act(states[-1], possible, env))\n",
    "            \n",
    "            observation, reward, done, inf = env.step(env.action_from_int(actions[-1]))\n",
    "            states.append([deepcopy(env.board)])\n",
    "            if done:\n",
    "                if abs(reward)==10:\n",
    "                    k += 1\n",
    "                    if reward == -10:\n",
    "                        xo[0] += 1\n",
    "                    else:\n",
    "                        xo[1] += 1\n",
    "                if turn == 1:\n",
    "                    agent1.update((states[1], actions[1], states[2], reward, done))\n",
    "                    agent2.update((states[0], actions[0], states[2], reward, done))\n",
    "                else:\n",
    "                    agent2.update((states[1], actions[1], states[2], reward, done))\n",
    "                    agent1.update((states[0], actions[0], states[2], reward, done))\n",
    "            else:            \n",
    "                if turn == 1:\n",
    "                    agent2.update((states[0], actions[0], states[2], reward, done))\n",
    "                else:\n",
    "                    agent1.update((states[0], actions[0], states[2], reward, done))\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        if i % 10000==0:\n",
    "            print(k)\n",
    "            print(xo)\n",
    "            k = 0\n",
    "            xo = [0, 0]\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a66a9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = DQN()\n",
    "agent2 = DQN(player=-1)\n",
    "env = TicTacToe(n_rows=3, n_cols=3, n_win=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21e2f3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                               | 0/1000000 [00:00<?, ?it/s]/tmp/ipykernel_4088/99110887.py:34: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  action = np.array(action, dtype=np.int)\n",
      "  0%|                                     | 8/1000000 [00:00<3:42:28, 74.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                | 10011/1000000 [03:09<4:03:51, 67.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8695\n",
      "[4329, 4366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                | 20007/1000000 [06:07<5:04:33, 53.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8986\n",
      "[4406, 4580]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▉                                | 30009/1000000 [08:54<5:27:57, 49.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9040\n",
      "[4525, 4515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▎                               | 40007/1000000 [12:02<5:56:46, 44.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6845\n",
      "[4135, 2710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█▋                               | 50011/1000000 [15:21<4:39:43, 56.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197\n",
      "[2515, 2682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█▉                               | 60008/1000000 [18:34<5:22:56, 48.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "[2828, 4172]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▎                              | 70007/1000000 [21:49<6:37:23, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9293\n",
      "[2980, 6313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██▋                              | 80005/1000000 [25:16<5:32:20, 46.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8127\n",
      "[3814, 4313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██▉                              | 90007/1000000 [28:37<4:34:21, 55.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5008\n",
      "[2395, 2613]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▏                            | 100006/1000000 [31:56<5:47:51, 43.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5239\n",
      "[2931, 2308]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███▌                            | 110008/1000000 [35:08<4:57:10, 49.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4995\n",
      "[2508, 2487]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███▊                            | 120012/1000000 [38:21<4:14:44, 57.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3536\n",
      "[1979, 1557]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|████▏                           | 130009/1000000 [41:30<4:24:04, 54.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4376\n",
      "[2332, 2044]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████▍                           | 140007/1000000 [45:11<5:47:03, 41.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4984\n",
      "[2203, 2781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████▊                           | 150007/1000000 [48:34<5:21:55, 44.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4108\n",
      "[2222, 1886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████                           | 160007/1000000 [51:43<4:21:05, 53.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3538\n",
      "[1942, 1596]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████▍                          | 170008/1000000 [54:55<4:19:23, 53.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430\n",
      "[1523, 1907]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████▊                          | 180010/1000000 [58:23<4:28:19, 50.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5147\n",
      "[2503, 2644]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████▋                        | 190006/1000000 [1:01:43<4:35:35, 48.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4518\n",
      "[2102, 2416]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████                        | 200012/1000000 [1:05:08<4:04:44, 54.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6407\n",
      "[2579, 3828]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██████▎                       | 210010/1000000 [1:08:25<4:22:03, 50.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3610\n",
      "[1609, 2001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████▌                       | 220005/1000000 [1:11:54<5:10:30, 41.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3611\n",
      "[1903, 1708]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██████▉                       | 230009/1000000 [1:15:35<4:23:16, 48.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4078\n",
      "[2289, 1789]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████▏                      | 240007/1000000 [1:19:48<5:09:31, 40.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8050\n",
      "[5553, 2497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████▌                      | 250006/1000000 [1:24:07<6:20:34, 32.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5005\n",
      "[3229, 1776]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████▊                      | 260008/1000000 [1:27:57<4:17:57, 47.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6023\n",
      "[3820, 2203]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████                      | 270010/1000000 [1:31:29<4:26:33, 45.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4068\n",
      "[1840, 2228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████▍                     | 280005/1000000 [1:35:21<4:32:45, 43.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3488\n",
      "[1992, 1496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████▋                     | 290009/1000000 [1:39:32<4:03:05, 48.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3248\n",
      "[1781, 1467]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████                     | 300007/1000000 [1:42:59<3:51:03, 50.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3455\n",
      "[1976, 1479]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████▎                    | 310010/1000000 [1:46:02<3:31:26, 54.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5117\n",
      "[2162, 2955]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████▌                    | 320011/1000000 [1:49:13<3:21:13, 56.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022\n",
      "[2796, 4226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████▉                    | 330008/1000000 [1:52:22<3:43:28, 49.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4155\n",
      "[2302, 1853]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████▏                   | 340012/1000000 [1:55:22<3:07:36, 58.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4784\n",
      "[2197, 2587]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████▌                   | 350010/1000000 [1:58:30<3:25:22, 52.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4374\n",
      "[2660, 1714]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████▊                   | 360006/1000000 [2:01:40<3:27:02, 51.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7952\n",
      "[3426, 4526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████                   | 370006/1000000 [2:04:52<3:09:08, 55.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5609\n",
      "[3274, 2335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████▍                  | 380006/1000000 [2:08:13<3:32:38, 48.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5929\n",
      "[3490, 2439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███████████▋                  | 390011/1000000 [2:11:25<2:59:53, 56.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4078\n",
      "[2878, 1200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████                  | 400005/1000000 [2:14:28<3:19:39, 50.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418\n",
      "[2148, 1270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████▎                 | 410009/1000000 [2:17:28<3:00:12, 54.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5817\n",
      "[3802, 2015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████▌                 | 420012/1000000 [2:20:34<2:49:59, 56.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4733\n",
      "[3108, 1625]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████▉                 | 430007/1000000 [2:23:43<2:48:17, 56.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4407\n",
      "[2423, 1984]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████▏                | 440011/1000000 [2:26:48<2:40:19, 58.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2931\n",
      "[1541, 1390]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████▌                | 450009/1000000 [2:30:01<3:23:55, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3409\n",
      "[1875, 1534]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████▊                | 460011/1000000 [2:33:12<2:43:46, 54.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3557\n",
      "[1947, 1610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████                | 470007/1000000 [2:36:25<2:51:11, 51.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4855\n",
      "[2752, 2103]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████▍               | 480009/1000000 [2:39:41<2:50:22, 50.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6320\n",
      "[3417, 2903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████▋               | 490011/1000000 [2:42:56<2:34:09, 55.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4268\n",
      "[2064, 2204]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████               | 500013/1000000 [2:46:23<2:22:35, 58.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4860\n",
      "[2075, 2785]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████▎              | 510008/1000000 [2:49:40<2:26:43, 55.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5452\n",
      "[3098, 2354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████▌              | 520009/1000000 [2:52:56<2:56:56, 45.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5865\n",
      "[3979, 1886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|███████████████▉              | 530007/1000000 [2:56:11<3:20:39, 39.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5904\n",
      "[3793, 2111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████▏             | 540007/1000000 [2:59:45<2:30:28, 50.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4259\n",
      "[2808, 1451]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████▌             | 550007/1000000 [3:03:12<2:46:49, 44.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5757\n",
      "[3589, 2168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████▊             | 560008/1000000 [3:06:11<2:20:31, 52.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6473\n",
      "[4103, 2370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████             | 570009/1000000 [3:09:26<2:11:35, 54.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6519\n",
      "[4204, 2315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████▍            | 580009/1000000 [3:12:37<1:57:50, 59.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656\n",
      "[2267, 1389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████████████████▋            | 590012/1000000 [3:16:11<2:08:56, 53.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4557\n",
      "[2997, 1560]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████            | 600007/1000000 [3:19:30<2:14:40, 49.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3447\n",
      "[2182, 1265]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████████████████▎           | 610011/1000000 [3:22:24<1:55:48, 56.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6268\n",
      "[4100, 2168]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████▌           | 620005/1000000 [3:25:37<1:59:18, 53.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4333\n",
      "[2706, 1627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████████████████▉           | 630008/1000000 [3:28:41<1:55:16, 53.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4579\n",
      "[3219, 1360]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████▏          | 640009/1000000 [3:31:46<1:58:51, 50.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4202\n",
      "[3291, 911]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████▌          | 650007/1000000 [3:34:59<1:44:58, 55.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3852\n",
      "[2732, 1120]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████▊          | 660008/1000000 [3:38:14<1:36:26, 58.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6893\n",
      "[4945, 1948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████          | 670009/1000000 [3:41:33<1:42:42, 53.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6566\n",
      "[5063, 1503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████▍         | 680009/1000000 [3:44:56<1:58:53, 44.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6930\n",
      "[5629, 1301]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████▋         | 690007/1000000 [3:48:16<1:56:09, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6807\n",
      "[4926, 1881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████         | 700005/1000000 [3:51:29<1:58:33, 42.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4656\n",
      "[3153, 1503]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████▎        | 710007/1000000 [3:54:58<1:36:19, 50.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6157\n",
      "[4945, 1212]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████▌        | 720007/1000000 [3:58:09<1:57:32, 39.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4274\n",
      "[2921, 1353]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████▊        | 725480/1000000 [4:00:29<1:30:59, 50.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4088/1101359883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4088/3231639752.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(agent1, agent2, env, steps)\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0magent2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4088/99110887.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, transition)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m9\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mPER_UPDATE\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossible\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4088/99110887.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mQT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msmooth_l1_loss\u001b[0;34m(input, target, size_average, reduce, reduction, beta)\u001b[0m\n\u001b[1;32m   3018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3020\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(agent1, agent2, env, int(1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600ab3f",
   "metadata": {},
   "source": [
    "Очень долго я боролся с этой задачей, но завести её так и не получилось. Пробовал разный размер буфера опыта, различные константы, soft- и hard- обновление таргет-сети. Однако, сеть всё равно не обучается не ставить х и o на запрещенные позиции (там, где уже стоят значки). В процессе обучения, выводимое число - это кол-во игр, которые закончились, потому что агент поставил значок на занятую позицию. Видно, что со временем это число падает, так что скорее всего, если усложнить сеть и и добавить больше эпох, то она обучится. Также я пришёл к выводу, что размер батча лучше оставить равным единице. При обучениие dqn на различных компьютерных играх последовательные стейты не сильно отличаются друг от друга, а здесь каждый стейт особенный."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fa1dd",
   "metadata": {},
   "source": [
    "# Часть 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "601aff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98063c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rollouts:\n",
    "    def __init__(self, player=1):\n",
    "        self.player = player\n",
    "    \n",
    "    def rand_policy(self, possib):\n",
    "        idx = np.random.randint(len(possib))\n",
    "        return possib[idx]\n",
    "    \n",
    "    def smart_policy(self, env, possib): #если можем закончить игру - заканчиваем\n",
    "        for ac in possib:\n",
    "            cop = TicTacToe(clone=env)\n",
    "            if cop.step(ac)[2]:\n",
    "                return ac\n",
    "        return self.rand_policy(possib)\n",
    "        \n",
    "    \n",
    "    def roll(self, env):\n",
    "        temp_env = TicTacToe(clone=env)\n",
    "        _, empty, turn = temp_env.getState()\n",
    "        reward = temp_env.isTerminal()\n",
    "        done = reward is not None\n",
    "        while not done:\n",
    "            #action = self.rand_policy(empty)\n",
    "            action = self.smart_policy(env, empty)\n",
    "            observation, reward, done, _ = temp_env.step(action)\n",
    "            empty = observation[1]\n",
    "        reward *= self.player\n",
    "        return reward\n",
    "    \n",
    "    def n_roll_outs(self, env, n=100):\n",
    "        results = 0\n",
    "        for _ in range(n):\n",
    "            res = self.roll(env)\n",
    "            results += res\n",
    "        return results / n\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4896078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "        self.parent = None\n",
    "        self.childs = []\n",
    "        self.nxt_states_set = set()\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.state.env.getHash().__hash__()\n",
    "    \n",
    "#     def __repr__(self):\n",
    "#         self.state.env.printBoard()\n",
    "#         return ''\n",
    "        \n",
    "    \n",
    "    def __str__(self):\n",
    "        self.state.env.printBoard()\n",
    "        print('visits', self.state.visits)\n",
    "        print('score', self.state.score)\n",
    "        return ''\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc33df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.visits = 0\n",
    "        self.score = 0\n",
    "    \n",
    "    def next_states(self):\n",
    "        if self.env.isTerminal():\n",
    "            return None\n",
    "        _, empty, _ = self.env.getState()\n",
    "        states = []\n",
    "        for act in empty:\n",
    "            temp = TicTacToe(clone=self.env)\n",
    "            temp.step(act)\n",
    "            states.append(State(temp))\n",
    "        return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2835de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, n_cols, n_rows, n_wins, player=1):\n",
    "        env = TicTacToe(n_rows, n_cols, n_wins)\n",
    "        state = State(env)\n",
    "        self.root = Node(state)\n",
    "        self.current_node = self.root\n",
    "        self.ro = Rollouts(player)\n",
    "        self.player = player\n",
    "        if player < 0:\n",
    "            self.run(n_cols*n_rows)\n",
    "    \n",
    "    def utb(self, node):\n",
    "        if node.state.visits == 0:\n",
    "            return 1e9\n",
    "        utb_score = -1 if self.player==node.state.env.curTurn else 1\n",
    "        utb_score *= node.state.score / node.state.visits\n",
    "        utb_score += 1.41 * (log(node.parent.state.visits) / node.state.visits)**0.5\n",
    "        return utb_score\n",
    "    \n",
    "    def choose_next(self, nodes):\n",
    "        scores = []\n",
    "        for nxt in nodes:\n",
    "            scores.append(self.utb(nxt))\n",
    "        return nodes[np.array(scores).argmax()]\n",
    "    \n",
    "    def selection(self, node, path=None):\n",
    "        if not path:\n",
    "            path = []\n",
    "        path.append(node)\n",
    "        if node.state.env.gameOver:\n",
    "            return path\n",
    "\n",
    "        if len(node.childs) != len(node.state.next_states()):\n",
    "            return path\n",
    "        nxt = self.choose_next(node.childs)\n",
    "        return self.selection(nxt, path)\n",
    "    \n",
    "    def expansion(self, node):\n",
    "        if node.state.env.gameOver:\n",
    "            return node\n",
    "        states = node.state.next_states()\n",
    "        for state in states:\n",
    "            if state.env.getHash() not in node.nxt_states_set:\n",
    "                new_node = Node(state)\n",
    "                node.childs.append(new_node)\n",
    "                node.nxt_states_set.add(new_node.state.env.getHash())\n",
    "                new_node.parent = node\n",
    "                break\n",
    "        return new_node\n",
    "    \n",
    "    def simulation(self, node):\n",
    "        if node.state.env.gameOver:\n",
    "            rew = node.state.env.curTurn * -1 * self.player * len(node.state.env.getEmptySpaces())\n",
    "            node.state.visits += 1\n",
    "            node.state.score += rew\n",
    "            #print(node.state.env.isTerminal())\n",
    "            return rew\n",
    "        mean_reward = self.ro.n_roll_outs(node.state.env)\n",
    "        node.state.visits += 1\n",
    "        node.state.score += mean_reward\n",
    "        return mean_reward\n",
    "    \n",
    "    def backup(self, path, reward):\n",
    "        for node in path[::-1]:\n",
    "            node.state.visits += 1\n",
    "            node.state.score += reward * 0.9\n",
    "    \n",
    "    def run(self, n=1):\n",
    "        for _ in range(n):\n",
    "            path = self.selection(self.current_node)\n",
    "            new_node = self.expansion(path[-1])\n",
    "            rew = self.simulation(new_node)\n",
    "            self.backup(path, rew)\n",
    "    \n",
    "    def step(self, n=100):\n",
    "        self.run(n)\n",
    "        max_rew = -10\n",
    "        action = None\n",
    "        for node in self.current_node.childs:\n",
    "            score = node.state.score / node.state.visits\n",
    "            if score > max_rew:\n",
    "                max_rew = score\n",
    "                nxt_node = node\n",
    "        \n",
    "        action = np.argmax(np.abs(self.current_node.state.env.board - nxt_node.state.env.board))\n",
    "        self.current_node = nxt_node\n",
    "        return action, nxt_node.state\n",
    "        \n",
    "        \n",
    "    def opponent_step(self, state):\n",
    "        st_hash = state.env.getHash()\n",
    "        if st_hash in self.current_node.nxt_states_set:\n",
    "            for node in self.current_node.childs:\n",
    "                if st_hash == node.state.env.getHash():\n",
    "                    self.current_node = node\n",
    "                    return\n",
    "        copied_env = TicTacToe(clone=state.env)\n",
    "        new_state = State(copied_env)\n",
    "        new_node = Node(new_state)\n",
    "        new_node.parent = self.current_node\n",
    "        self.current_node.childs.append(new_node)\n",
    "        self.current_node.nxt_states_set.add(new_node.state.env.getHash())\n",
    "        self.current_node = new_node\n",
    "        return\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_node = self.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b62cb552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc01c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(agent1, agent2, env):\n",
    "    agent1.reset()\n",
    "    agent2.reset()\n",
    "    env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        #clear_output()\n",
    "        env.printBoard()\n",
    "        sleep(1)\n",
    "        ac, state = agent1.step(100)\n",
    "        _, _, done, _ = env.step(env.action_from_int(ac))\n",
    "        if done:\n",
    "            break\n",
    "        #clear_output()\n",
    "        env.printBoard()\n",
    "        sleep(1)\n",
    "        agent2.opponent_step(state)\n",
    "        ac, state = agent2.step(100)\n",
    "        _, _, done, _ = env.step(env.action_from_int(ac))\n",
    "        if done:\n",
    "            break\n",
    "        agent1.opponent_step(state)\n",
    "    #clear_output()\n",
    "    env.printBoard()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5cfc56ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag1 = MCTS(3, 3, 3)\n",
    "ag2 = MCTS(3,3,3,-1)\n",
    "env = TicTacToe(3,3,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5eda04",
   "metadata": {},
   "source": [
    "в качестве доказательства работоспособности кода я решил смодулировать игру в крестики-нолики 3х3. При больших размерах нужно проводить больше запусков цикла (selection-expansion-simulating-backup), что занимает намного больше времени. В 3х3 MSTS всегда выходит на ничью, как и должно быть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f9b28aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | x | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "play(ag1, ag2, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0dc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
